<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>JARVIS Vision Call</title>
  <style>
    body {
      margin: 0;
      overflow: hidden;
      background: black;
      color: white;
      font-family: 'Segoe UI', sans-serif;
    }
    video, canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      object-fit: cover;
      z-index: 1;
    }
    #overlayBox {
      position: absolute;
      bottom: 20px;
      left: 20px;
      background: rgba(0, 0, 0, 0.7);
      padding: 15px;
      border: 2px solid #00ffcc;
      max-width: 420px;
      font-size: 16px;
      z-index: 3;
    }
    #switchBtn, #languageBtn, #micBtn {
      position: absolute;
      top: 20px;
      padding: 10px 20px;
      background: #00ffcc;
      border: none;
      color: black;
      font-weight: bold;
      border-radius: 5px;
      cursor: pointer;
      z-index: 4;
    }
    #switchBtn { left: 20px; }
    #languageBtn { right: 20px; }
    #micBtn { top: 70px; right: 20px; }
  </style>
</head>
<body>
  <video id="webcam" autoplay muted playsinline></video>
  <canvas id="canvas"></canvas>
  <button id="switchBtn">Switch Camera</button>
  <button id="languageBtn">Convert to Hindi</button>
  <button id="micBtn">Activate Mic</button>
  <div id="overlayBox">JARVIS is online...</div>

  <script>
    const video = document.getElementById('webcam');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const overlayBox = document.getElementById('overlayBox');
    const switchBtn = document.getElementById('switchBtn');
    const languageBtn = document.getElementById('languageBtn');
    const micBtn = document.getElementById('micBtn');

    let stream;
    let apiKey = '';
    let usingFrontCamera = false;
    let analyzing = false;
    let currentLanguage = 'en';
    let recognition;

    fetch("api.txt")
      .then(res => res.text())
      .then(key => apiKey = key.trim());

    async function setupWebcam() {
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }

      const constraints = {
        video: {
          facingMode: usingFrontCamera ? "user" : "environment"
        },
        audio: false
      };

      stream = await navigator.mediaDevices.getUserMedia(constraints);
      video.srcObject = stream;

      return new Promise(resolve => {
        video.onloadedmetadata = () => resolve();
      });
    }

    function speak(text, lang = 'en') {
      const synth = window.speechSynthesis;
      synth.cancel();
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = lang === 'hi' ? 'hi-IN' : 'en-US';
      synth.speak(utterance);
    }

    async function captureFrame() {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      return new Promise((resolve) => {
        canvas.toBlob(blob => {
          const reader = new FileReader();
          reader.onloadend = () => resolve(reader.result.split(',')[1]);
          reader.readAsDataURL(blob);
        }, 'image/jpeg');
      });
    }

    async function scanWithGemini() {
      if (analyzing) return;
      analyzing = true;
      overlayBox.innerText = currentLanguage === 'hi' ? "à¤µà¤¿à¤¶à¥à¤²à¥‡à¤·à¤£ à¤•à¤¿à¤¯à¤¾ à¤œà¤¾ à¤°à¤¹à¤¾ à¤¹à¥ˆ..." : "Analyzing...";

      const base64Image = await captureFrame();

      try {
        const response = await fetch(
          `https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent?key=${apiKey}`,
          {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              contents: [{
                parts: [
                  { inlineData: { mimeType: 'image/jpeg', data: base64Image } },
                  { text: "What do you see in this image in simple terms?" }
                ]
              }]
            })
          }
        );

        const data = await response.json();
        const message = data?.candidates?.[0]?.content?.parts?.[0]?.text || (currentLanguage === 'hi' ? "à¤›à¤µà¤¿ à¤•à¤¾ à¤µà¤¿à¤¶à¥à¤²à¥‡à¤·à¤£ à¤¨à¤¹à¥€à¤‚ à¤•à¤¿à¤¯à¤¾ à¤œà¤¾ à¤¸à¤•à¤¾à¥¤" : "Could not analyze image.");

        overlayBox.innerText = message;
        speak(message, currentLanguage);
      } catch (err) {
        overlayBox.innerText = currentLanguage === 'hi' ? "à¤µà¤¿à¤¶à¥à¤²à¥‡à¤·à¤£ à¤µà¤¿à¤«à¤² à¤°à¤¹à¤¾à¥¤" : "Failed to analyze.";
        console.error(err);
      } finally {
        analyzing = false;
      }
    }

    function startVoiceCommandOnce() {
      if (!('webkitSpeechRecognition' in window || 'SpeechRecognition' in window)) {
        overlayBox.innerText = "ðŸŽ™ï¸ Voice recognition not supported.";
        return;
      }

      if (recognition) recognition.abort();

      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognition = new SpeechRecognition();
      recognition.lang = currentLanguage === 'hi' ? 'hi-IN' : 'en-US';
      recognition.interimResults = false;
      recognition.continuous = false;

      recognition.onresult = (event) => {
        const transcript = event.results[0][0].transcript.trim().toLowerCase();
        console.log("Heard:", transcript);
        const keywords = ["what is this", "ye kya hai", "à¤¯à¤¹ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ", "à¤µà¥à¤¹à¤¾à¤Ÿ à¤‡à¤¸ à¤¦à¤¿à¤¸"];
        if (keywords.some(k => transcript.includes(k))) {
          scanWithGemini();
        } else {
          overlayBox.innerText = currentLanguage === 'hi' ? "à¤•à¥‹à¤ˆ à¤®à¤¾à¤¨à¥à¤¯ à¤•à¤®à¤¾à¤‚à¤¡ à¤¨à¤¹à¥€à¤‚ à¤®à¤¿à¤²à¥€à¥¤" : "No valid command heard.";
        }
      };

      recognition.onerror = (e) => {
        console.warn("Speech error:", e.error);
        recognition.stop();
      };

      recognition.onend = () => {
        console.warn("Speech recognition ended.");
      };

      recognition.start();
      overlayBox.innerText = currentLanguage === 'hi' ? "ðŸŽ¤ à¤¸à¥à¤¨ à¤°à¤¹à¤¾ à¤¹à¥ˆ..." : "ðŸŽ¤ Listening...";
    }

    switchBtn.addEventListener('click', () => {
      usingFrontCamera = !usingFrontCamera;
      setupWebcam();
    });

    languageBtn.addEventListener('click', () => {
      currentLanguage = currentLanguage === 'en' ? 'hi' : 'en';
      languageBtn.innerText = currentLanguage === 'en' ? 'Convert to Hindi' : 'Convert to English';
      overlayBox.innerText = currentLanguage === 'hi' ? "JARVIS à¤‘à¤¨à¤²à¤¾à¤‡à¤¨ à¤¹à¥ˆ..." : "JARVIS is online...";
    });

    micBtn.addEventListener('click', () => {
      setTimeout(() => startVoiceCommandOnce(), 300);
    });

    setupWebcam().then(() => {
      requestAnimationFrame(updateVideoCanvas);
    });

    function updateVideoCanvas() {
      if (video.readyState >= 2) {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      }
      requestAnimationFrame(updateVideoCanvas);
    }
  </script>
</body>
</html>
