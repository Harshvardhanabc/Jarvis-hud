<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>JARVIS HUD</title>
  <style>
    body {
      margin: 0;
      overflow: hidden;
      background: black;
      font-family: 'Segoe UI', sans-serif;
      color: white;
    }
    video {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      object-fit: cover;
      z-index: 1;
      transform: scaleX(-1);
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
      z-index: 2;
    }
    #descriptionBox {
      position: absolute;
      bottom: 30px;
      left: 30px;
      background: rgba(0, 0, 0, 0.7);
      padding: 15px;
      border: 2px solid #00ffcc;
      max-width: 400px;
      font-size: 16px;
      z-index: 3;
    }
  </style>

  <!-- Load TensorFlow.js and COCO-SSD -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.2/dist/coco-ssd.min.js"></script>
</head>
<body>
  <video id="webcam" autoplay muted playsinline></video>
  <canvas id="canvas"></canvas>
  <div id="descriptionBox">JARVIS is initializing...</div>

  <script>
    const video = document.getElementById('webcam');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const descBox = document.getElementById('descriptionBox');

    let model;
    const detectedLabels = {};

    async function setupWebcam() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      return new Promise(resolve => {
        video.onloadedmetadata = () => resolve(video);
      });
    }

    async function explain(label) {
      const now = Date.now();
      if (detectedLabels[label] && now - detectedLabels[label] < 10000) return;
      detectedLabels[label] = now;

      const response = await fetch(
        'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=AIzaSyDgaov6JpEyBAI2cqOqpBPD_JXieo9yjNY',
        {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            contents: [{ parts: [{ text: `What is a ${label} in simple terms?` }] }]
          })
        }
      );

      const data = await response.json();
      const message = data.candidates?.[0]?.content?.parts?.[0]?.text || 'Could not explain.';
      descBox.innerText = `${label.toUpperCase()}: ${message}`;
      
      const synth = window.speechSynthesis;
      synth.cancel();
      synth.speak(new SpeechSynthesisUtterance(`${label}. ${message}`));
    }

    async function detectFrame() {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      const predictions = await model.detect(video);
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      predictions.forEach(pred => {
        const [x, y, width, height] = pred.bbox;
        ctx.strokeStyle = '#00ffcc';
        ctx.lineWidth = 2;
        ctx.strokeRect(x, y, width, height);
        ctx.fillStyle = '#00ffcc';
        ctx.font = '16px Segoe UI';
        ctx.fillText(pred.class, x, y > 20 ? y - 5 : y + 15);

        explain(pred.class);
      });

      requestAnimationFrame(detectFrame);
    }

    async function main() {
      await setupWebcam();
      model = await cocoSsd.load(); // Fixed: uses global cocoSsd from script
      detectFrame();
    }

    main();
  </script>
</body>
</html>
